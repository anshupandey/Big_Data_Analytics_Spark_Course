{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# MLflow and Spark Integration\n",
        "\n",
        "This document details the conceptual integration of MLflow with Apache Spark for machine learning workflows, specifically focusing on a 5G Quality of Service (QoS) dataset.\n",
        "\n",
        "## MLflow Overview\n",
        "\n",
        "MLflow is an open-source platform designed to manage the entire machine learning lifecycle.  Its key components address distinct challenges in ML development:\n",
        "\n",
        "* **Tracking:** MLflow Tracking provides a centralized repository for experiments.  It logs parameters, code versions, metrics, and artifacts (models, plots, etc.) associated with each run. This allows for easy comparison of different model versions and hyperparameter settings, promoting reproducibility and facilitating the selection of the best-performing model.  In the context of a 5G QoS dataset, this could track the performance of different algorithms (e.g., regression, classification) with various hyperparameters on metrics relevant to QoS, such as latency, throughput, and packet loss.\n",
        "\n",
        "* **Projects:** MLflow Projects define reproducible, reusable workflows.  Projects specify the code, dependencies, and environment required to run an ML experiment, ensuring consistency across different environments (local, cloud, etc.).  For the 5G QoS dataset, a project could encapsulate data preprocessing steps, model training, and evaluation using Spark, ensuring that the entire pipeline can be easily rerun or deployed.  This is particularly crucial when working with large datasets typical in 5G network analysis.\n",
        "\n",
        "* **Models:** MLflow Models provide a standard format for packaging and deploying machine learning models.  The format supports various model flavors (e.g., scikit-learn, TensorFlow, PyTorch) and deployment targets (e.g., REST API, batch inference).  Once a model trained on the 5G QoS dataset is selected via tracking, it can be packaged into an MLflow Model for deployment to a production environment, such as a system monitoring network performance. This ensures consistency between training and inference.\n",
        "\n",
        "* **Registry:** The MLflow Model Registry enables centralized model management, including versioning, stage transitions (e.g., staging, production), and annotations.  This component facilitates model governance and simplifies the deployment process. In the context of the 5G QoS data, different versions of QoS prediction models can be managed and deployed, with detailed notes about performance characteristics and the dataset used for training.\n",
        "\n",
        "## Spark Integration\n",
        "\n",
        "Apache Spark's distributed computing capabilities are crucial for handling large-scale datasets like those encountered in 5G network analysis. Integrating MLflow with Spark offers several advantages:\n",
        "\n",
        "* **Scalable Model Training:** Spark's distributed processing allows for parallel model training on large 5G QoS datasets.  MLflow can track the training process across the Spark cluster, consolidating metrics and artifacts from each executor.\n",
        "\n",
        "* **Data Preprocessing with Spark:** Spark's DataFrame API provides tools for efficient data preparation and feature engineering. MLflow Projects can leverage these capabilities to preprocess the 5G data, ensuring consistency and reproducibility before model training.  Preprocessing steps (cleaning, transformation, feature extraction) can be logged in MLflow, enabling better understanding and reproducibility of results.\n",
        "\n",
        "\n",
        "* **Model Deployment with Spark:** MLflow Models can be deployed in a Spark environment for real-time or batch inference. This facilitates integration into existing Spark-based data pipelines. A deployed model can analyze incoming 5G QoS data streams, enabling real-time monitoring and anomaly detection.\n",
        "\n",
        "* **Unified Workflow:**  The integration combines Spark's data processing prowess with MLflow's ML lifecycle management, streamlining the end-to-end workflow for 5G QoS analysis.  This unified platform supports the development, deployment, and monitoring of QoS models.\n",
        "\n",
        "\n",
        "By combining MLflow's experiment management and model deployment capabilities with Spark's distributed computing power, it becomes possible to build robust, scalable machine learning pipelines for analyzing 5G QoS datasets.  The entire process, from data ingestion to model deployment, can be effectively managed and monitored, leading to faster iteration, greater reproducibility, and more reliable results.\n"
      ],
      "metadata": {
        "id": "51bHChi479HB"
      },
      "id": "51bHChi479HB"
    },
    {
      "cell_type": "markdown",
      "id": "d9b14693",
      "metadata": {
        "id": "d9b14693"
      },
      "source": [
        "# MLflow and Spark Integration with 5G Quality of Service Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99624b48",
      "metadata": {
        "id": "99624b48"
      },
      "outputs": [],
      "source": [
        "#installing required library\n",
        "!pip install pyspark mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52f75fc9",
      "metadata": {
        "id": "52f75fc9"
      },
      "outputs": [],
      "source": [
        "#Initializing spark session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MLflow_Spark_Integration_5G\") \\\n",
        "    .config(\"spark.jars.packages\", \"org.mlflow:mlflow-spark:2.8.0\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark session initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38a225fc",
      "metadata": {
        "id": "38a225fc"
      },
      "outputs": [],
      "source": [
        "#Loading and preprocessing dataset\n",
        "from pyspark.sql.functions import regexp_replace, col\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"Quality of Service 5G.csv\"  # Update with the correct path\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Preprocess the data: Convert text-based numeric values to numeric types\n",
        "df = df.withColumn(\"Signal_Strength\", regexp_replace(col(\"Signal_Strength\"), \" dBm\", \"\").cast(\"float\")) \\\n",
        "       .withColumn(\"Latency\", regexp_replace(col(\"Latency\"), \" ms\", \"\").cast(\"float\")) \\\n",
        "       .withColumn(\"Required_Bandwidth\", regexp_replace(col(\"Required_Bandwidth\"), \" Mbps\", \"\").cast(\"float\")) \\\n",
        "       .withColumn(\"Allocated_Bandwidth\", regexp_replace(col(\"Allocated_Bandwidth\"), \" Mbps\", \"\").cast(\"float\")) \\\n",
        "       .withColumn(\"Resource_Allocation\", regexp_replace(col(\"Resource_Allocation\"), \"%\", \"\").cast(\"float\"))\n",
        "\n",
        "# Show the first few rows and schema\n",
        "df.show(5)\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab49ab2c",
      "metadata": {
        "id": "ab49ab2c"
      },
      "outputs": [],
      "source": [
        "#Defining ML pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index the Application_Type column (convert it to numeric categories)\n",
        "indexer = StringIndexer(inputCol=\"Application_Type\", outputCol=\"Application_Type_Indexed\")"
      ],
      "metadata": {
        "id": "re_Vh0vg8Yjc"
      },
      "id": "re_Vh0vg8Yjc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble features\n",
        "feature_columns = [\"Signal_Strength\", \"Latency\", \"Required_Bandwidth\", \"Allocated_Bandwidth\", \"Resource_Allocation\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")"
      ],
      "metadata": {
        "id": "h6f59EUX8YE3"
      },
      "id": "h6f59EUX8YE3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Model (example use case: predicting Application_Type)\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Application_Type_Indexed\", maxIter=10)\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline(stages=[indexer, assembler, lr])"
      ],
      "metadata": {
        "id": "i_9WjnNL8X2A"
      },
      "id": "i_9WjnNL8X2A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1edc306",
      "metadata": {
        "id": "f1edc306"
      },
      "outputs": [],
      "source": [
        "#Setting up MLFlow\n",
        "import mlflow\n",
        "import mlflow.spark\n",
        "\n",
        "# Set MLflow tracking URI (local or remote)\n",
        "mlflow.set_tracking_uri(\"http://localhost:5000\")  # Replace with your MLflow server URI\n",
        "\n",
        "# Set experiment name\n",
        "experiment_name = \"5G_Quality_of_Service_Experiment\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"Experiment Name: {experiment_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31dd54e1",
      "metadata": {
        "id": "31dd54e1"
      },
      "outputs": [],
      "source": [
        "#Training and Tracking the model\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "with mlflow.start_run():\n",
        "    # Split the data into training and test sets\n",
        "    train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "    # Fit the pipeline model\n",
        "    model = pipeline.fit(train_data)\n",
        "\n",
        "    # Log the Spark ML model\n",
        "    mlflow.spark.log_model(model, \"spark_model\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    predictions = model.transform(test_data)\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol=\"Application_Type_Indexed\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "    # Log metrics and parameters\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_param(\"model_type\", \"Logistic Regression\")\n",
        "\n",
        "    print(f\"Model accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a915ad9c",
      "metadata": {
        "id": "a915ad9c"
      },
      "outputs": [],
      "source": [
        "#Registering the model\n",
        "model_uri = f\"runs:/{mlflow.active_run().info.run_id}/spark_model\"\n",
        "registered_model_name = \"5G_QoS_Logistic_Regression\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.register_model(model_uri, registered_model_name)\n",
        "print(f\"Model registered as: {registered_model_name}\")"
      ],
      "metadata": {
        "id": "UglJVT7-9IQL"
      },
      "id": "UglJVT7-9IQL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f71082e1",
      "metadata": {
        "id": "f71082e1"
      },
      "outputs": [],
      "source": [
        "#Deploying the model\n",
        "\n",
        "# Load the model back in Spark and use it for predictions\n",
        "loaded_model = mlflow.spark.load_model(f\"models:/{registered_model_name}/1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model for prediction on new data\n",
        "new_predictions = loaded_model.transform(test_data)\n",
        "new_predictions.show(5)"
      ],
      "metadata": {
        "id": "paLaZsQS9DgW"
      },
      "id": "paLaZsQS9DgW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e656fb43",
      "metadata": {
        "id": "e656fb43"
      },
      "outputs": [],
      "source": [
        "#Visualizing the results\n",
        "!mlflow ui\n",
        "\n",
        "#Access the UI at http://localhost:5000."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}