{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab6: Spark ML: Clustering and Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tasks\n",
        "1. **Install and Configure PySpark:**\n",
        "    - Install the PySpark library.\n",
        "    - Import necessary modules from PySpark.\n",
        "\n",
        "2. **Start Spark Session:**\n",
        "    - Initialize a Spark session for clustering and recommendation tasks.\n",
        "\n",
        "3. **Load and Simulate Telecom Data:**\n",
        "    - Define a schema for the telecom dataset.\n",
        "    - Create a Spark DataFrame with sample telecom data.\n",
        "\n",
        "4. **Display the Dataset:**\n",
        "    - Show the contents of the telecom dataset.\n",
        "\n",
        "5. **Clustering:**\n",
        "    - Combine features into a single vector using `VectorAssembler`.\n",
        "    - Build and train a KMeans clustering model.\n",
        "    - Assign clusters to customers and display the cluster assignments.\n",
        "\n",
        "6. **Recommendation System (ALS):**\n",
        "    - Simulate user-item interaction data for the recommendation system.\n",
        "    - Define a schema for the recommendation dataset.\n",
        "    - Create a Spark DataFrame with the recommendation data.\n",
        "    - Initialize and train the ALS model.\n",
        "    - Generate and display recommendations for customers.\n",
        "    - Generate and display recommendations for plans.\n",
        "\n",
        "7. **Project - Customer Segmentation Analysis:**\n",
        "    - Load the telecom segmentation dataset from an Excel file.\n",
        "    - Convert the Pandas DataFrame to a Spark DataFrame.\n",
        "    - Display the schema and preview the data.\n",
        "    - Select features for clustering.\n",
        "    - Assemble features into a single vector column.\n",
        "    - Apply KMeans clustering to the dataset.\n",
        "    - Assign clusters to each customer and display the resulting clusters.\n",
        "    - Evaluate clustering performance using the Silhouette Score.\n",
        "\n",
        "8. **Practice Case Study - Clustering and Recommendation:**\n",
        "    - Repeat the clustering and recommendation tasks with a new set of sample data.\n",
        "\n",
        "9. **General Deployment Considerations:**\n",
        "    - Discuss scalability, performance optimization, monitoring, and A/B testing for the deployed models.\n",
        "\n",
        "10. **Stop Spark Session:**\n",
        "     - Stop the Spark session after completing all tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jHwhjY38AZ0"
      },
      "source": [
        "\n",
        "## Spark ML for Clustering and Recommendation Systems\n",
        "\n",
        "These notes detail the development and deployment of Clustering models and Recommendation Systems using Spark ML.\n",
        "\n",
        "### I. Clustering Models with Spark ML\n",
        "\n",
        "**A. Overview:**\n",
        "\n",
        "Clustering in Spark ML involves grouping similar data points together based on their features.  Spark ML provides algorithms like K-Means, Gaussian Mixture Models (GMM), and Bisecting K-Means. The choice of algorithm depends on the data distribution and desired cluster characteristics.\n",
        "\n",
        "**B. Data Preparation:**\n",
        "\n",
        "1. **Data Loading:** Load data into a Spark DataFrame. Ensure data is properly formatted and features are numerical.  Categorical features need encoding (e.g., one-hot encoding, string indexer) before use in most clustering algorithms.\n",
        "\n",
        "2. **Feature Scaling:**  Scale features to prevent features with larger values from dominating the distance calculations.  Common scaling methods include standardization (z-score normalization) and MinMaxScaler.\n",
        "\n",
        "3. **Feature Selection:**  Select relevant features for clustering.  Dimensionality reduction techniques (PCA) can be applied to reduce noise and improve performance, especially with high-dimensional data.\n",
        "\n",
        "**C. Model Development:**\n",
        "\n",
        "1. **Algorithm Selection:** Choose an appropriate algorithm:\n",
        "    * **K-Means:** Simple, efficient, and widely used. Requires specifying the number of clusters (k).\n",
        "    * **Gaussian Mixture Models (GMM):** Assumes data points are generated from a mixture of Gaussian distributions.  Can identify clusters with different shapes and sizes.\n",
        "    * **Bisecting K-Means:**  A hierarchical clustering algorithm that repeatedly bisects the largest cluster.\n",
        "\n",
        "2. **Parameter Tuning:** Optimize model parameters using techniques like cross-validation or grid search. Key parameters include:\n",
        "    * **K-Means:** `k`, `maxIterations`, `initMode`, `tol`\n",
        "    * **GMM:**  `k`, `maxIterations`, `tol`\n",
        "    * **Bisecting K-Means:** `k`, `maxIterations`, `minDivisibleClusterSize`\n",
        "\n",
        "3. **Model Training:** Fit the chosen algorithm to the preprocessed data.\n",
        "\n",
        "\n",
        "**D. Model Evaluation:**\n",
        "\n",
        "1. **Silhouette Score:** Measures how similar a data point is to its own cluster compared to other clusters.  Higher scores indicate better clustering.\n",
        "\n",
        "2. **Calinski-Harabasz Index:** Ratio of the between-cluster dispersion mean and the within-cluster dispersion mean.  Higher scores indicate better clustering.\n",
        "\n",
        "3. **Davies-Bouldin Index:**  Measures the average similarity between each cluster and its most similar cluster.  Lower scores indicate better clustering.\n",
        "\n",
        "**E. Deployment:**\n",
        "\n",
        "1. **Model Persistence:** Save the trained model to disk for later use.\n",
        "\n",
        "2. **Model Prediction:** Use the saved model to predict cluster assignments for new data.\n",
        "\n",
        "3. **Integration:** Integrate the clustering model into a larger application or pipeline.\n",
        "\n",
        "\n",
        "\n",
        "### II. Recommendation Systems with Spark ML\n",
        "\n",
        "**A. Overview:**\n",
        "\n",
        "Recommendation systems aim to predict user preferences for items.  Spark MLlib provides collaborative filtering algorithms like Alternating Least Squares (ALS).\n",
        "\n",
        "**B. Data Preparation:**\n",
        "\n",
        "1. **Data Loading:**  Load user-item interaction data into a Spark DataFrame.  This typically includes user IDs, item IDs, and ratings or implicit feedback (e.g., purchase history).\n",
        "\n",
        "2. **Data Splitting:** Split the data into training, validation, and test sets.\n",
        "\n",
        "\n",
        "**C. Model Development:**\n",
        "\n",
        "1. **Algorithm Selection:** ALS is a common choice for collaborative filtering.\n",
        "\n",
        "2. **Parameter Tuning:** Optimize parameters using the validation set. Key parameters:\n",
        "    * **rank:** Number of latent factors.\n",
        "    * **maxIter:** Maximum number of iterations.\n",
        "    * **regParam:** Regularization parameter.\n",
        "    * **alpha:**  Parameter for implicit feedback (only relevant for implicit feedback data).\n",
        "\n",
        "3. **Model Training:** Train the ALS model on the training data.\n",
        "\n",
        "\n",
        "**D. Model Evaluation:**\n",
        "\n",
        "1. **Root Mean Squared Error (RMSE):**  Measures the difference between predicted and actual ratings.  Lower values indicate better performance.\n",
        "2. **Mean Absolute Error (MAE):**  Similar to RMSE but uses absolute differences.\n",
        "3. **Precision and Recall:** Evaluate the quality of recommendations based on the top-N recommendations.\n",
        "\n",
        "**E. Deployment:**\n",
        "\n",
        "1. **Model Persistence:** Save the trained model.\n",
        "\n",
        "2. **Real-time Recommendations:** Deploy the model for real-time predictions using a serving layer (e.g., REST API).\n",
        "\n",
        "3. **Batch Recommendations:** Generate recommendations in batches for offline analysis or updates.\n",
        "\n",
        "\n",
        "\n",
        "**III. General Deployment Considerations**\n",
        "\n",
        "* **Scalability:** Spark's distributed computing capabilities are crucial for handling large datasets.\n",
        "* **Performance:** Optimize data pipelines and model parameters for efficient processing.\n",
        "* **Monitoring:** Monitor the model's performance over time and retrain as needed.\n",
        "* **A/B Testing:** Experiment with different models and parameters to find the optimal configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz-EVKNOV9sW"
      },
      "source": [
        "##Case Study - Clustering recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTVofcz-8GDy",
        "outputId": "33d31614-9d9b-4b2d-a447-21c2f74e0312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "#Install and Configure PySpark\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#Start Spark session\n",
        "spark = SparkSession.builder.appName(\"TelecomClusteringRecommendation\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MmWMV-X8RYZ"
      },
      "outputs": [],
      "source": [
        "#Load and Simulate Telecom Data\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
        "\n",
        "# Simulate a telecom dataset\n",
        "data = [\n",
        "    (1, 20, 500, 15, 50, 3),\n",
        "    (2, 45, 1000, 50, 200, 5),\n",
        "    (3, 30, 600, 20, 80, 2),\n",
        "    (4, 25, 300, 10, 30, 1),\n",
        "    (5, 40, 900, 40, 150, 4),\n",
        "]\n",
        "schema = StructType([\n",
        "    StructField(\"CustomerID\", IntegerType(), True),\n",
        "    StructField(\"Age\", IntegerType(), True),\n",
        "    StructField(\"MonthlyUsage\", IntegerType(), True),\n",
        "    StructField(\"CallFrequency\", IntegerType(), True),\n",
        "    StructField(\"DataUsage\", IntegerType(), True),\n",
        "    StructField(\"PlanID\", IntegerType(), True),\n",
        "])\n",
        "df = spark.createDataFrame(data, schema=schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAYUS8OP9WpJ",
        "outputId": "aea38d43-c195-4056-b91a-0889ebf70eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---+------------+-------------+---------+------+\n",
            "|CustomerID|Age|MonthlyUsage|CallFrequency|DataUsage|PlanID|\n",
            "+----------+---+------------+-------------+---------+------+\n",
            "|         1| 20|         500|           15|       50|     3|\n",
            "|         2| 45|        1000|           50|      200|     5|\n",
            "|         3| 30|         600|           20|       80|     2|\n",
            "|         4| 25|         300|           10|       30|     1|\n",
            "|         5| 40|         900|           40|      150|     4|\n",
            "+----------+---+------------+-------------+---------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display data\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQguK10m9YBB"
      },
      "outputs": [],
      "source": [
        "#Clustering\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnnLFvFv9gWy"
      },
      "outputs": [],
      "source": [
        "#Combine features into a single vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"Age\", \"MonthlyUsage\", \"CallFrequency\", \"DataUsage\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "data_with_features = assembler.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLrFF3vb9hgD"
      },
      "outputs": [],
      "source": [
        "#Build and train the KMeans model\n",
        "kmeans = KMeans(k=3, seed=123, featuresCol=\"features\", predictionCol=\"cluster\")\n",
        "kmeans_model = kmeans.fit(data_with_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgyO8CuR9q4E",
        "outputId": "f9530284-3b25-4382-e7fc-a3398b12b7c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------------------+-------+\n",
            "|CustomerID|            features|cluster|\n",
            "+----------+--------------------+-------+\n",
            "|         1|[20.0,500.0,15.0,...|      2|\n",
            "|         2|[45.0,1000.0,50.0...|      1|\n",
            "|         3|[30.0,600.0,20.0,...|      2|\n",
            "|         4|[25.0,300.0,10.0,...|      0|\n",
            "|         5|[40.0,900.0,40.0,...|      1|\n",
            "+----------+--------------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Assign clusters to customers\n",
        "clusters = kmeans_model.transform(data_with_features)\n",
        "clusters.select(\"CustomerID\", \"features\", \"cluster\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4gu66NX9tWx"
      },
      "outputs": [],
      "source": [
        "#Recommendation System (ALS)\n",
        "from pyspark.ml.recommendation import ALS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuGODTYl9uZe"
      },
      "outputs": [],
      "source": [
        "#Simulate user-item interaction data (customer plan usage)\n",
        "recommendation_data = [\n",
        "    (1, 1, 4.0),\n",
        "    (1, 2, 2.0),\n",
        "    (2, 1, 5.0),\n",
        "    (2, 3, 3.0),\n",
        "    (3, 2, 4.0),\n",
        "    (3, 3, 1.0),\n",
        "    (4, 1, 3.0),\n",
        "    (4, 2, 5.0),\n",
        "    (5, 3, 4.0),\n",
        "]\n",
        "rec_schema = StructType([\n",
        "    StructField(\"CustomerID\", IntegerType(), True),\n",
        "    StructField(\"PlanID\", IntegerType(), True),\n",
        "    StructField(\"Rating\", FloatType(), True),\n",
        "])\n",
        "rec_df = spark.createDataFrame(recommendation_data, schema=rec_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GmU68L_93fl"
      },
      "outputs": [],
      "source": [
        "# Initialize and train ALS model\n",
        "als = ALS(\n",
        "    userCol=\"CustomerID\",\n",
        "    itemCol=\"PlanID\",\n",
        "    ratingCol=\"Rating\",\n",
        "    maxIter=10,\n",
        "    regParam=0.1,\n",
        "    rank=10,\n",
        "    coldStartStrategy=\"drop\"\n",
        ")\n",
        "als_model = als.fit(rec_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8cV-167-F9n",
        "outputId": "3236f2d7-48cf-4007-9cbe-691ffe4c68f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------------------------------------------------+\n",
            "|CustomerID|recommendations                                 |\n",
            "+----------+------------------------------------------------+\n",
            "|1         |[{1, 3.8783436}, {3, 2.6226692}, {2, 2.0328445}]|\n",
            "|2         |[{1, 4.859957}, {2, 3.4273922}, {3, 3.0245786}] |\n",
            "|3         |[{2, 3.8877108}, {1, 2.56783}, {3, 1.0166105}]  |\n",
            "|4         |[{2, 4.847688}, {1, 3.025969}, {3, 1.1368906}]  |\n",
            "|5         |[{1, 5.419569}, {3, 3.8903399}, {2, 2.561105}]  |\n",
            "+----------+------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate recommendations for customers\n",
        "customer_recommendations = als_model.recommendForAllUsers(3)\n",
        "customer_recommendations.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMEL_nkL-PCI",
        "outputId": "163fccba-d7cf-4562-ea8c-1f99ba658359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------------------------------------+\n",
            "|PlanID|recommendations                                 |\n",
            "+------+------------------------------------------------+\n",
            "|1     |[{5, 5.419569}, {2, 4.859957}, {1, 3.8783436}]  |\n",
            "|2     |[{4, 4.847688}, {3, 3.8877108}, {2, 3.4273922}] |\n",
            "|3     |[{5, 3.8903399}, {2, 3.0245786}, {1, 2.6226692}]|\n",
            "+------+------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate recommendations for plans\n",
        "plan_recommendations = als_model.recommendForAllItems(3)\n",
        "plan_recommendations.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L4P9AePKFct"
      },
      "source": [
        "##Project - Customer Segmentation analysis\n",
        "\n",
        "Telecom companies operate in a competitive market, where retaining customers and optimizing services is key to success. The goal of this analysis is to segment customers into meaningful clusters based on their usage patterns. These clusters can help in better understanding customer behavior and personalizing services.\n",
        "\n",
        "The objective is to use KMeans clustering to group customers based on their usage metrics:\n",
        "\n",
        "- Monthly bill amount\n",
        "- Average call duration\n",
        "- Data usage in GB\n",
        "- Number of calls\n",
        "- Customer tenure\n",
        "\n",
        "The output clusters will help the telecom company to understand behavioral patterns. Develop targeted strategies for customer satisfaction and revenue growth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfZuGYC_KE4s",
        "outputId": "d596f5a9-db9a-4bb9-a538-25d3bc1a3906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "#Install PySpark and Required Libraries\n",
        "!pip install pyspark openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ypxZoP-KE13"
      },
      "outputs": [],
      "source": [
        "#Initialize Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTrAx4cgKEzJ"
      },
      "outputs": [],
      "source": [
        "#Start a Spark session\n",
        "spark = SparkSession.builder.appName(\"TelecomClustering\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBvIVHhIKEwY"
      },
      "outputs": [],
      "source": [
        "#Load the Dataset\n",
        "import pandas as pd\n",
        "\n",
        "#Upload the dataset file to Colab (ensure it's named 'telecom_segmentation_data.xlsx')\n",
        "data = pd.read_excel(\"/content/telecom_segmentation_data (1).xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbTAL4YgKEtp"
      },
      "outputs": [],
      "source": [
        "#Convert Pandas DataFrame to Spark DataFrame\n",
        "df = spark.createDataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEk2YgKZKEq0",
        "outputId": "907806fe-4d58-4871-ae3c-b9421fddf0b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Customer_ID: long (nullable = true)\n",
            " |-- Monthly_Bill_Amount: double (nullable = true)\n",
            " |-- Average_Call_Duration: double (nullable = true)\n",
            " |-- Segment: string (nullable = true)\n",
            " |-- Data_Usage_GB: double (nullable = true)\n",
            " |-- Number_of_Calls: long (nullable = true)\n",
            " |-- Customer_Tenure: long (nullable = true)\n",
            "\n",
            "+-----------+-------------------+---------------------+---------+-----------------+---------------+---------------+\n",
            "|Customer_ID|Monthly_Bill_Amount|Average_Call_Duration|  Segment|    Data_Usage_GB|Number_of_Calls|Customer_Tenure|\n",
            "+-----------+-------------------+---------------------+---------+-----------------+---------------+---------------+\n",
            "|          1|  45.09054491313347|                  2.0|Low Usage|19.35246582352076|            118|              9|\n",
            "|          2|  46.92616129684993|    2.757929853910177|Low Usage|47.58500101408589|            125|              1|\n",
            "|          3|  38.72679256500254|    2.475610187744059|Low Usage|36.86770314875885|            103|              5|\n",
            "|          4|  44.20372715870461|    3.773873013788232|Low Usage| 30.3342657256548|             56|              4|\n",
            "|          5|  43.30131172868862|    4.153892792681296|Low Usage| 8.64491338167939|            108|              3|\n",
            "|          6|  46.86872130445768|    5.898063982274204|Low Usage| 8.64373149647393|             64|              6|\n",
            "|          7|  47.61773257207395|    7.051378129107696|Low Usage|3.846096996241774|            177|              2|\n",
            "|          8|  35.16465007380228|    2.078373777926174|Low Usage|43.44263114297183|             61|              3|\n",
            "|          9|  43.83487829603229|    6.915594270696306|Low Usage|30.45463557541723|            153|              5|\n",
            "|         10|  35.65410573704899|    2.420368232143316|Low Usage|35.69555631200623|             22|              9|\n",
            "|         11|  41.62969337862494|    6.881339816820644|Low Usage| 2.00864022049432|            123|              2|\n",
            "|         12|  38.30509180614585|    4.773301315544028|Low Usage|48.52558275593772|            133|              8|\n",
            "|         13|  38.33037000752451|    5.175501388161244|Low Usage|41.78968939922066|            115|              2|\n",
            "|         14|  38.59228499722317|    5.889205852044088|Low Usage|11.40461642323553|            167|              5|\n",
            "|         15|  40.87636416181559|    9.233209064315322|Low Usage| 9.90942339314793|            156|              7|\n",
            "|         16|  37.90651986092287|    6.081636032255295|Low Usage|9.986820982818257|            154|              8|\n",
            "|         17|  40.79446399347847|    11.33889523679641|Low Usage|15.90786990501735|            129|              1|\n",
            "|         18|  37.86569874739932|    7.348580369311164|Low Usage|26.71306514997966|             72|              6|\n",
            "|         19|  35.42592418393223|    2.932643869802221|Low Usage|22.16530591346367|             28|              1|\n",
            "|         20|  39.19569633229391|    12.98221369727369|Low Usage|15.27022786970405|            101|              2|\n",
            "+-----------+-------------------+---------------------+---------+-----------------+---------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Display the schema and preview the data\n",
        "df.printSchema()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58rOToBCKEoD"
      },
      "outputs": [],
      "source": [
        "#Select Features for Clustering\n",
        "feature_cols = [\"Monthly_Bill_Amount\", \"Average_Call_Duration\", \"Data_Usage_GB\", \"Number_of_Calls\", \"Customer_Tenure\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zkEHG7oKEll"
      },
      "outputs": [],
      "source": [
        "#Assemble features into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "df_features = assembler.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_3M6qZAKEi0"
      },
      "outputs": [],
      "source": [
        "#Apply KMeans Clustering\n",
        "kmeans = KMeans(featuresCol=\"features\", predictionCol=\"cluster\", k=3, seed=42)  # Specify the number of clusters (k)\n",
        "kmeans_model = kmeans.fit(df_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD8xQbRFN2tZ"
      },
      "outputs": [],
      "source": [
        "#Assign Clusters to Each Customer\n",
        "df_clusters = kmeans_model.transform(df_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrYNjtgQN2p2",
        "outputId": "1aa4d593-e7a8-4819-cc99-15c903b5625d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------------------+-------+\n",
            "|Customer_ID|            features|cluster|\n",
            "+-----------+--------------------+-------+\n",
            "|          1|[45.0905449131334...|      2|\n",
            "|          2|[46.9261612968499...|      2|\n",
            "|          3|[38.7267925650025...|      2|\n",
            "|          4|[44.2037271587046...|      0|\n",
            "|          5|[43.3013117286886...|      2|\n",
            "|          6|[46.8687213044576...|      0|\n",
            "|          7|[47.6177325720739...|      2|\n",
            "|          8|[35.1646500738022...|      0|\n",
            "|          9|[43.8348782960322...|      2|\n",
            "|         10|[35.6541057370489...|      0|\n",
            "|         11|[41.6296933786249...|      2|\n",
            "|         12|[38.3050918061458...|      2|\n",
            "|         13|[38.3303700075245...|      2|\n",
            "|         14|[38.5922849972231...|      2|\n",
            "|         15|[40.8763641618155...|      2|\n",
            "|         16|[37.9065198609228...|      2|\n",
            "|         17|[40.7944639934784...|      2|\n",
            "|         18|[37.8656987473993...|      0|\n",
            "|         19|[35.4259241839322...|      0|\n",
            "|         20|[39.1956963322939...|      2|\n",
            "+-----------+--------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Display the resulting clusters\n",
        "df_clusters.select(\"Customer_ID\", \"features\", \"cluster\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n1DiFA_N2nc",
        "outputId": "1e9c2095-526f-4b65-de0c-408df62132f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Silhouette Score: 0.5630\n"
          ]
        }
      ],
      "source": [
        "#Evaluate Clustering Performance using Silhouette Score\n",
        "evaluator = ClusteringEvaluator(featuresCol=\"features\", predictionCol=\"cluster\", metricName=\"silhouette\")\n",
        "silhouette_score = evaluator.evaluate(df_clusters)\n",
        "\n",
        "print(f\"Silhouette Score: {silhouette_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTd7RhbmJy3R"
      },
      "source": [
        "##Practice Case Study - Clustering and Recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4PQcOpGATX2"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# data = [\n",
        "    (1, 20, 500, 15, 50, 3),\n",
        "    (2, 45, 1000, 50, 200, 5),\n",
        "    (3, 30, 600, 20, 80, 2),\n",
        "    (4, 25, 300, 10, 30, 1),\n",
        "    (5, 40, 900, 40, 150, 4),\n",
        "    (6, 22, 700, 25, 100, 3),\n",
        "    (7, 50, 1200, 60, 250, 5),\n",
        "    (8, 35, 800, 30, 120, 4),\n",
        "    (9, 28, 400, 12, 40, 1),\n",
        "    (10, 42, 1100, 45, 180, 5)\n",
        "]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfCvtL9iO3FJ"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.recommendation import ALS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F44Xb3XbO2QT",
        "outputId": "b772aa64-ca86-413c-d782-c8211e1cb1a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Install and Configure PySpark (if not already installed)\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDcye0voCGsu"
      },
      "outputs": [],
      "source": [
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"TelecomClusteringRecommendation\").getOrCreate()\n",
        "\n",
        "# Load and Simulate Telecom Data\n",
        "# Sample data\n",
        "data = [\n",
        "    (1, 20, 500, 15, 50, 3),\n",
        "    (2, 45, 1000, 50, 200, 5),\n",
        "    (3, 30, 600, 20, 80, 2),\n",
        "    (4, 25, 300, 10, 30, 1),\n",
        "    (5, 40, 900, 40, 150, 4),\n",
        "    (6, 22, 700, 25, 100, 3),\n",
        "    (7, 50, 1200, 60, 250, 5),\n",
        "    (8, 35, 800, 30, 120, 4),\n",
        "    (9, 28, 400, 12, 40, 1),\n",
        "    (10, 42, 1100, 45, 180, 5)\n",
        "]\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"CustomerID\", IntegerType(), True),\n",
        "    StructField(\"Age\", IntegerType(), True),\n",
        "    StructField(\"MonthlyUsage\", IntegerType(), True),\n",
        "    StructField(\"CallFrequency\", IntegerType(), True),\n",
        "    StructField(\"DataUsage\", IntegerType(), True),\n",
        "    StructField(\"PlanID\", IntegerType(), True),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIYzI3Y1O-qO"
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame(data, schema=schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8R9b2Z_PFOu",
        "outputId": "0c132840-8544-40cd-bb5d-fc236aea7840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Telecom Dataset:\n",
            "+----------+---+------------+-------------+---------+------+\n",
            "|CustomerID|Age|MonthlyUsage|CallFrequency|DataUsage|PlanID|\n",
            "+----------+---+------------+-------------+---------+------+\n",
            "|         1| 20|         500|           15|       50|     3|\n",
            "|         2| 45|        1000|           50|      200|     5|\n",
            "|         3| 30|         600|           20|       80|     2|\n",
            "|         4| 25|         300|           10|       30|     1|\n",
            "|         5| 40|         900|           40|      150|     4|\n",
            "|         6| 22|         700|           25|      100|     3|\n",
            "|         7| 50|        1200|           60|      250|     5|\n",
            "|         8| 35|         800|           30|      120|     4|\n",
            "|         9| 28|         400|           12|       40|     1|\n",
            "|        10| 42|        1100|           45|      180|     5|\n",
            "+----------+---+------------+-------------+---------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display the dataset\n",
        "print(\"Sample Telecom Dataset:\")\n",
        "df.show()\n",
        "\n",
        "#Clustering\n",
        "# Combine features into a single vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"Age\", \"MonthlyUsage\", \"CallFrequency\", \"DataUsage\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "data_with_features = assembler.transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPUC8NDtPFLR"
      },
      "outputs": [],
      "source": [
        "# Build and train the KMeans model\n",
        "kmeans = KMeans(k=3, seed=123, featuresCol=\"features\", predictionCol=\"cluster\") # setting k=3\n",
        "kmeans_model = kmeans.fit(data_with_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zWvWRuHPFI3",
        "outputId": "55d4fe3d-3de4-4f84-db47-29079976c150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster assignments:\n",
            "+----------+--------------------+-------+\n",
            "|CustomerID|            features|cluster|\n",
            "+----------+--------------------+-------+\n",
            "|         1|[20.0,500.0,15.0,...|      1|\n",
            "|         2|[45.0,1000.0,50.0...|      0|\n",
            "|         3|[30.0,600.0,20.0,...|      1|\n",
            "|         4|[25.0,300.0,10.0,...|      1|\n",
            "|         5|[40.0,900.0,40.0,...|      2|\n",
            "|         6|[22.0,700.0,25.0,...|      2|\n",
            "|         7|[50.0,1200.0,60.0...|      0|\n",
            "|         8|[35.0,800.0,30.0,...|      2|\n",
            "|         9|[28.0,400.0,12.0,...|      1|\n",
            "|        10|[42.0,1100.0,45.0...|      0|\n",
            "+----------+--------------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Assign clusters to customers\n",
        "clusters = kmeans_model.transform(data_with_features)\n",
        "print(\"Cluster assignments:\")\n",
        "clusters.select(\"CustomerID\", \"features\", \"cluster\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuHMtxyIPTuC"
      },
      "outputs": [],
      "source": [
        "#Recommendation System (ALS)\n",
        "#Simulate user-item interaction data\n",
        "recommendation_data = [\n",
        "    (1, 1, 4.0), (1, 2, 2.0), (2, 1, 5.0), (2, 3, 3.0), (3, 2, 4.0),\n",
        "    (3, 3, 1.0), (4, 1, 3.0), (4, 2, 5.0), (5, 3, 4.0), (6, 2, 3.0),\n",
        "    (7, 3, 5.0), (8, 1, 2.0), (9, 2, 4.0), (10,3, 5.0)\n",
        "]\n",
        "\n",
        "\n",
        "rec_schema = StructType([\n",
        "    StructField(\"CustomerID\", IntegerType(), True),\n",
        "    StructField(\"PlanID\", IntegerType(), True),\n",
        "    StructField(\"Rating\", FloatType(), True),\n",
        "])\n",
        "\n",
        "rec_df = spark.createDataFrame(recommendation_data, schema=rec_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acowTzr5PTqj"
      },
      "outputs": [],
      "source": [
        "# Initialize and train ALS model\n",
        "als = ALS(\n",
        "    userCol=\"CustomerID\",\n",
        "    itemCol=\"PlanID\",\n",
        "    ratingCol=\"Rating\",\n",
        "    maxIter=10,\n",
        "    regParam=0.1,\n",
        "    rank=10,\n",
        "    coldStartStrategy=\"drop\"\n",
        ")\n",
        "\n",
        "als_model = als.fit(rec_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlZHxz_jPTjf",
        "outputId": "359e0f28-b5d0-4254-eaa9-1cf34a860cd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommendations for all users:\n",
            "+----------+------------------------------------------------+\n",
            "|CustomerID|recommendations                                 |\n",
            "+----------+------------------------------------------------+\n",
            "|10        |[{3, 4.926397}, {1, 3.2402215}, {2, 1.7122594}] |\n",
            "|1         |[{1, 3.85063}, {3, 2.7237918}, {2, 2.0484934}]  |\n",
            "|2         |[{1, 4.8521023}, {2, 3.6179414}, {3, 3.0074117}]|\n",
            "|3         |[{2, 3.885463}, {1, 2.6564176}, {3, 1.0096402}] |\n",
            "|4         |[{2, 4.8412123}, {1, 3.0279834}, {3, 1.2310266}]|\n",
            "|5         |[{3, 3.9411175}, {1, 2.5921772}, {2, 1.3698076}]|\n",
            "|6         |[{2, 2.95763}, {1, 2.1223497}, {3, 0.985676}]   |\n",
            "|7         |[{3, 4.926397}, {1, 3.2402215}, {2, 1.7122594}] |\n",
            "|8         |[{1, 1.9709389}, {2, 1.4556934}, {3, 1.2793583}]|\n",
            "|9         |[{2, 3.9435065}, {1, 2.8298}, {3, 1.3142346}]   |\n",
            "+----------+------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate recommendations for customers\n",
        "customer_recommendations = als_model.recommendForAllUsers(3)\n",
        "print(\"Recommendations for all users:\")\n",
        "customer_recommendations.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeI7VOukPTgE",
        "outputId": "0fe5d631-32a9-48bc-c63b-cc4d987c280b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommendations for all plans:\n",
            "+------+-----------------------------------------------+\n",
            "|PlanID|recommendations                                |\n",
            "+------+-----------------------------------------------+\n",
            "|1     |[{2, 4.8521023}, {1, 3.85063}, {10, 3.2402215}]|\n",
            "|2     |[{4, 4.8412123}, {9, 3.9435065}, {3, 3.885463}]|\n",
            "|3     |[{10, 4.926397}, {7, 4.926397}, {5, 3.9411175}]|\n",
            "+------+-----------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate recommendations for plans\n",
        "plan_recommendations = als_model.recommendForAllItems(3)\n",
        "print(\"Recommendations for all plans:\")\n",
        "plan_recommendations.show(truncate=False)\n",
        "\n",
        "\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDZ3kL9IPTa0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
